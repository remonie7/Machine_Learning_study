```python
# 출력을 원하실 경우 print() 활용
# 예) print(df.head())

# 답안 제출 예시
# 수험번호.csv 생성
# DataFrame.to_csv("0000.csv", index=False)

import pandas as pd
import numpy as np

x_train = pd.read_csv("data/X_train.csv")
y_train = pd.read_csv("data/y_train.csv")
x_test = pd.read_csv("data/X_test.csv")

fitdata=pd.concat([x_train, x_test])
fitdata_num=fitdata[['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '구매주기']]

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(fitdata_num)

train=pd.merge(x_train, y_train, on="cust_id")

train=train.fillna(0)
train['총구매액']=[0 if x<0 else x for x in train['총구매액']]
train['최대구매액']=[0 if x<0 else x for x in train['최대구매액']]
train[['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '구매주기']]=scaler.transform(train[['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '구매주기']])

iqr_1=np.percentile(train['총구매액'], 75)+(np.percentile(train['총구매액'], 75)-np.percentile(train['총구매액'], 25))*1.5
iqr_2=np.percentile(train['최대구매액'], 75)+(np.percentile(train['최대구매액'], 75)-np.percentile(train['최대구매액'], 25))*1.5
iqr_3=np.percentile(train['환불금액'], 75)+(np.percentile(train['환불금액'], 75)-np.percentile(train['환불금액'], 25))*1.5
iqr_4=np.percentile(train['내점일수'], 75)+(np.percentile(train['내점일수'], 75)-np.percentile(train['내점일수'], 25))*1.5
iqr_5=np.percentile(train['내점당구매건수'], 75)+(np.percentile(train['내점당구매건수'], 75)-np.percentile(train['내점당구매건수'], 25))*1.5
iqr_6=np.percentile(train['구매주기'], 75)+(np.percentile(train['구매주기'], 75)-np.percentile(train['구매주기'], 25))*1.5

train['총구매액']=[iqr_1 if x>iqr_1 else x for x in train['총구매액']]
train['최대구매액']=[iqr_2 if x>iqr_2 else x for x in train['최대구매액']]
train['환불금액']=[iqr_3 if x>iqr_3 else x for x in train['환불금액']]
train['내점일수']=[iqr_4 if x>iqr_4 else x for x in train['내점일수']]
train['내점당구매건수']=[iqr_5 if x>iqr_5 else x for x in train['내점당구매건수']]
train['구매주기']=[iqr_6 if x>iqr_6 else x for x in train['구매주기']]

train['총구매액']=np.log((train['총구매액']+1))
train['최대구매액']=np.log((train['최대구매액']+1))
train['환불금액']=np.log((train['환불금액']+1))
train['내점일수']=np.log((train['내점일수']+1))
train['내점당구매건수']=np.log((train['내점당구매건수']+1))
train['구매주기']=np.log((train['구매주기']+1))


train.drop(['cust_id','내점당구매건수', '주말방문비율', '구매주기'], axis=1, inplace=True)

del_str_1=['소형가전', '악기', '보석', '남성 트랜디', '통신/컴퓨터', '침구/수예', '액세서리', '대형가전', '식기', '커리어', '가구', '란제리/내의']
del_str_2=['상인점', '전주점', '창원점', '대구점', '센텀시티점', '울산점', '포항점']
train['주구매상품']=['기타' if x in del_str_1 else x for x in train['주구매상품']]
train['주구매지점']=['기타' if x in del_str_2 else x for x in train['주구매지점']]

train=pd.get_dummies(train, columns=['주구매상품'])
train=pd.get_dummies(train, columns=['주구매지점'])
corr_gender=train.corr()['gender'].to_frame()
del_col=corr_gender[(corr_gender['gender']<=0.05) & (corr_gender['gender']>=-0.05)].index
train.drop(del_col, axis=1, inplace=True)




from sklearn.model_selection import train_test_split
train_data, val_data=train_test_split(train, test_size=0.2, random_state=42)
train_x=train_data.drop('gender', axis=1)
train_y=train_data['gender']
val_x=val_data.drop('gender', axis=1)
val_y=val_data['gender']

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
param_grid_glm = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}
glm_grid_search = GridSearchCV(LogisticRegression(), param_grid=param_grid_glm, cv=5, n_jobs=-1) 
glm_grid_search.fit(train_x, train_y) 
print("로지스틱회귀")
print("best param : {}".format(glm_grid_search.best_params_))  #C:1
print("best acc : {}".format(glm_grid_search.best_score_)) #0.66
print(glm_grid_search.score(train_x, train_y)) #0.66
print(glm_grid_search.score(val_x, val_y)) #0.67
print(roc_auc_score(val_y, glm_grid_search.predict(val_x))) #0.62


from sklearn.ensemble import RandomForestClassifier
#param_grid_rf = {'max_depth': range(1,7),
#                'min_samples_split':range(2,7)}
#rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring="accuracy") 
#rf_grid_search.fit(train_x, train_y) 
#print("랜덤포레스트")
#print("best param : {}".format(rf_grid_search.best_params_))  #6, 4
#print("best acc : {}".format(rf_grid_search.best_score_)) #0.66
#print(rf_grid_search.score(train_x, train_y)) #0.68
#print(rf_grid_search.score(val_x, val_y)) #0.65
#print(roc_auc_score(val_y, rf_grid_search.predict(val_x))) #0.60

from sklearn.svm import SVC
#param_grid_svm = {'C': [0.1, 1, 10, 100]}
#svm_grid_search = GridSearchCV(SVC(gamma='auto'), param_grid=param_grid_svm, cv=5, n_jobs=-1, scoring="accuracy") 
#svm_grid_search.fit(train_x, train_y) 
#print("SVM")
#print("best param : {}".format(svm_grid_search.best_params_))  # c:100
#print("best acc : {}".format(svm_grid_search.best_score_)) #0.65
#print(svm_grid_search.score(train_x, train_y)) #0.66
#print(svm_grid_search.score(val_x, val_y)) #0.67
#print(roc_auc_score(val_y, svm_grid_search.predict(val_x))) #0.62

#from sklearn.ensemble import VotingClassifier
#glm=LogisticRegression(C=1)
#rf=RandomForestClassifier(max_depth=6, min_samples_split=4)
#svm=SVC(C=100)
#voting=VotingClassifier(
#estimators=[('lr', glm), ('rf', rf), ('svm', svm)], voting='hard')
#voting.fit(train_x, train_y)
#print(voting.score(train_x, train_y)) #0.67
#print(voting.score(val_x, val_y)) #0.66
#print(roc_auc_score(val_y, voting.predict(val_x))) #0.61


#######################




x_test=x_test.fillna(0)
x_test['총구매액']=[0 if x<0 else x for x in x_test['총구매액']]
x_test['최대구매액']=[0 if x<0 else x for x in x_test['최대구매액']]
x_test[['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '구매주기']]=scaler.transform(x_test[['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '구매주기']])

iqr_1=np.percentile(x_test['총구매액'], 75)+(np.percentile(x_test['총구매액'], 75)-np.percentile(x_test['총구매액'], 25))*1.5
iqr_2=np.percentile(x_test['최대구매액'], 75)+(np.percentile(x_test['최대구매액'], 75)-np.percentile(x_test['최대구매액'], 25))*1.5
iqr_3=np.percentile(x_test['환불금액'], 75)+(np.percentile(x_test['환불금액'], 75)-np.percentile(x_test['환불금액'], 25))*1.5
iqr_4=np.percentile(x_test['내점일수'], 75)+(np.percentile(x_test['내점일수'], 75)-np.percentile(x_test['내점일수'], 25))*1.5
iqr_5=np.percentile(x_test['내점당구매건수'], 75)+(np.percentile(x_test['내점당구매건수'], 75)-np.percentile(x_test['내점당구매건수'], 25))*1.5
iqr_6=np.percentile(x_test['구매주기'], 75)+(np.percentile(x_test['구매주기'], 75)-np.percentile(x_test['구매주기'], 25))*1.5

x_test['총구매액']=[iqr_1 if x>iqr_1 else x for x in x_test['총구매액']]
x_test['최대구매액']=[iqr_2 if x>iqr_2 else x for x in x_test['최대구매액']]
x_test['환불금액']=[iqr_3 if x>iqr_3 else x for x in x_test['환불금액']]
x_test['내점일수']=[iqr_4 if x>iqr_4 else x for x in x_test['내점일수']]
x_test['내점당구매건수']=[iqr_5 if x>iqr_5 else x for x in x_test['내점당구매건수']]
x_test['구매주기']=[iqr_6 if x>iqr_6 else x for x in x_test['구매주기']]

x_test['총구매액']=np.log((x_test['총구매액']+1))
x_test['최대구매액']=np.log((x_test['최대구매액']+1))
x_test['환불금액']=np.log((x_test['환불금액']+1))
x_test['내점일수']=np.log((x_test['내점일수']+1))
x_test['내점당구매건수']=np.log((x_test['내점당구매건수']+1))
x_test['구매주기']=np.log((x_test['구매주기']+1))


x_test.drop(['cust_id','내점당구매건수', '주말방문비율', '구매주기'], axis=1, inplace=True)


x_test['주구매상품']=['기타' if x in del_str_1 else x for x in x_test['주구매상품']]
x_test['주구매지점']=['기타' if x in del_str_2 else x for x in x_test['주구매지점']]

x_test=pd.get_dummies(x_test, columns=['주구매상품'])
x_test=pd.get_dummies(x_test, columns=['주구매지점'])
x_test.drop(del_col, axis=1, inplace=True)


x_test1 = pd.read_csv("data/X_test.csv")
rst=pd.DataFrame({'custid':x_test1['cust_id'],
								 'gender':pd.DataFrame(glm_grid_search.predict_proba(x_test))[1]})
print(rst)
rst.to_csv("data/0000.csv", index=False)
```

